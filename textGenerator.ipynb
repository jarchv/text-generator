{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"spanish_emojis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>emojis</th>\n",
       "      <th>observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>üò≠</td>\n",
       "      <td>? en serio han cancelado tambien quantico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>si on mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>üòù</td>\n",
       "      <td>se duerme relooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>ü§ó</td>\n",
       "      <td>ahi te podes dar cuenta que diferentes somos y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>üò™</td>\n",
       "      <td>625 pero la tipi esta jugando desde la 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 emojis                                       observations\n",
       "0         300      üò≠          ? en serio han cancelado tambien quantico\n",
       "1         301      üòÇ                                           si on mo\n",
       "2         302      üòù                                   se duerme relooo\n",
       "3         303      ü§ó  ahi te podes dar cuenta que diferentes somos y...\n",
       "4         304      üò™           625 pero la tipi esta jugando desde la 5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151743"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = df['observations'].values\n",
    "len(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? en serio han cancelado tambien quantico'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sentence in observations:\n",
    "    sentences.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1427429"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_word_simbols = [word_simbol for sublist in sentences for word_simbol in sublist]\n",
    "\n",
    "len(flatten_word_simbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size =  66967\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "cnt = collections.Counter(flatten_word_simbols)\n",
    "print(\"Vocab size = \", len(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_keys = cnt.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sisieeeeeerto', 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_keys[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {}\n",
    "\n",
    "i = 0\n",
    "for word_simbol, count in vocab_keys:\n",
    "    stoi[word_simbol] = i\n",
    "    i+=1\n",
    "    \n",
    "stoi['_end_'  ] = i\n",
    "stoi['_blank_'] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1025, 22484, 66967, 66968)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['que'],stoi['ja'], stoi['.'],stoi['_end_'], stoi['_blank_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max key-value \t=  66968\n",
      "Vocab Size \t=  66969\n"
     ]
    }
   ],
   "source": [
    "print(\"Max key-value \\t= \", len(stoi.keys())-1)\n",
    "\n",
    "VOCAB_SIZE = len(stoi.keys())\n",
    "print(\"Vocab Size \\t= \", VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {}\n",
    "\n",
    "for s, i in stoi.items():\n",
    "    itos[i] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ('que'     == itos[stoi['que'    ]])\n",
    "assert ('ja'      == itos[stoi['ja'     ]])\n",
    "assert ('.'       == itos[stoi['.'      ]])\n",
    "assert ('_end_'   == itos[stoi['_end_'  ]])\n",
    "assert ('_blank_' == itos[stoi['_blank_']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input = []\n",
    "ls      = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    i_sentence = []\n",
    "    for word_simbol in sentence:\n",
    "        i_sentence.append(stoi[word_simbol])\n",
    "    i_sentence.append(stoi['_end_'])\n",
    "    x_input.append(i_sentence)\n",
    "    ls.append(len(i_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAXLEN : 50\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = max(ls)\n",
    "print('MAXLEN :',MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank Value =  66968\n"
     ]
    }
   ],
   "source": [
    "blank_value = stoi['_blank_']\n",
    "\n",
    "print('Blank Value = ', blank_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data train tensor: (151743, 50)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train = pad_sequences(x_input, maxlen = MAXLEN, value=blank_value)\n",
    "\n",
    "print('Shape of data train tensor:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq  = []\n",
    "y_train_next = []\n",
    "\n",
    "SEQ_LEN      = 3\n",
    "\n",
    "for x_input_obs in x_train:\n",
    "    for i in range(MAXLEN - SEQ_LEN):\n",
    "        if x_input_obs[i] != blank_value:\n",
    "            x_train_seq.append(x_input_obs[i:i+SEQ_LEN])\n",
    "            y_train_next.append(x_input_obs[i+SEQ_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras \n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads = 4,\n",
    "                        allow_soft_placement = True, \n",
    "                        device_count = {'CPU' : 1, 'GPU' : 0})\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 66969, 3)          0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 3)                 84        \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 66969)             267876    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 66969)             0         \n",
      "=================================================================\n",
      "Total params: 267,960\n",
      "Trainable params: 267,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_input = Input(shape=(VOCAB_SIZE, SEQ_LEN))\n",
    "\n",
    "#rnn       = Bidirectional(LSTM(SEQ_LEN, activation=\"relu\"))(seq_input)\n",
    "rnn       = LSTM(SEQ_LEN, activation=\"relu\")(seq_input)\n",
    "rnn       = Dropout(0.6)(rnn)\n",
    "rnn       = Dense(VOCAB_SIZE)(rnn)\n",
    "output    = Activation('softmax')(rnn)\n",
    "\n",
    "model     = Model(inputs=[seq_input], outputs=[output])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH 0 100\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 58s 582ms/step - loss: 11.1116 - acc: 0.0700\n",
      "BATCH 100 200\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 57s 574ms/step - loss: 11.1103 - acc: 0.0200\n",
      "BATCH 200 300\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 57s 569ms/step - loss: 11.1087 - acc: 0.0200\n",
      "BATCH 300 400\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 57s 568ms/step - loss: 11.1070 - acc: 0.0200\n",
      "BATCH 400 500\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 57s 573ms/step - loss: 11.1047 - acc: 0.1200\n",
      "BATCH 500 600\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 58s 576ms/step - loss: 11.1039 - acc: 0.1100\n",
      "BATCH 600 700\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 57s 573ms/step - loss: 11.1012 - acc: 0.1100\n",
      "BATCH 700 800\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 58s 576ms/step - loss: 11.1001 - acc: 0.1600\n",
      "BATCH 800 900\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 57s 574ms/step - loss: 11.0976 - acc: 0.1500\n",
      "BATCH 900 1000\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 57s 571ms/step - loss: 11.0940 - acc: 0.1400\n",
      "BATCH 1000 1100\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "filepath   =\"model/textG_best_weights_SIF.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "for ibatch in range(0, len(x_train_seq), BATCH_SIZE):\n",
    "    \n",
    "    i_begin = ibatch\n",
    "    i_end   = min(ibatch + BATCH_SIZE, len(x_train_seq))\n",
    "    \n",
    "    print('BATCH', i_begin, i_end)\n",
    "    x_train_one_hot = to_categorical( x_train_seq[i_begin:i_end], num_classes = VOCAB_SIZE)\n",
    "    y_train_one_hot = to_categorical(y_train_next[i_begin:i_end], num_classes = VOCAB_SIZE)\n",
    "    x_train_one_hot = np.reshape(x_train_one_hot, (x_train_one_hot.shape[0],VOCAB_SIZE, SEQ_LEN))\n",
    "    #model.fit(x_train_one_hot, y_train_one_hot, batch_size=64, epochs=1, callbacks = [checkpoint])   \n",
    "    model.fit(x_train_one_hot, y_train_one_hot, batch_size=64, epochs=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

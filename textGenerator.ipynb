{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textGenerator.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ALDvLowpumX3",
        "colab_type": "code",
        "outputId": "cffb39fb-569f-476c-fc0c-3a383e7c632f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "路路路路路路路路路路\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1MawPHZSvEZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = '/content/gdrive/My Drive/CS/SI/part2/text-generator/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H9jb4572ujzD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(DRIVE_PATH + \"spanish_emojis.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VxfxjGFhujzb",
        "colab_type": "code",
        "outputId": "b563ad7f-81cf-4db9-d806-d0d9555bcd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>emojis</th>\n",
              "      <th>observations</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300</td>\n",
              "      <td></td>\n",
              "      <td>? en serio han cancelado tambien quantico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>301</td>\n",
              "      <td></td>\n",
              "      <td>si on mo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>302</td>\n",
              "      <td></td>\n",
              "      <td>se duerme relooo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>303</td>\n",
              "      <td></td>\n",
              "      <td>ahi te podes dar cuenta que diferentes somos y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>304</td>\n",
              "      <td></td>\n",
              "      <td>625 pero la tipi esta jugando desde la 5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 emojis                                       observations\n",
              "0         300                ? en serio han cancelado tambien quantico\n",
              "1         301                                                 si on mo\n",
              "2         302                                         se duerme relooo\n",
              "3         303        ahi te podes dar cuenta que diferentes somos y...\n",
              "4         304                 625 pero la tipi esta jugando desde la 5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "bjNy5CiQujzt",
        "colab_type": "code",
        "outputId": "32bd2522-c883-423f-e8c1-4c913c46bf96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "observations = df['observations'].values\n",
        "len(observations)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151743"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "NESyBZ99ujz-",
        "colab_type": "code",
        "outputId": "eaafe884-8950-4154-cff2-74c157fedf68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "observations[0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'? en serio han cancelado tambien quantico'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "zOus-1euuj0L",
        "colab_type": "code",
        "outputId": "955d078d-6375-4bef-9a8b-38a674f78781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for sentence in observations:\n",
        "    if len(sentence.split()) > 18:\n",
        "      sentences.append(sentence.split())\n",
        "      \n",
        "print(len(sentences))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bg0cOyjnvdSE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = sentences[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MZUjgxnfuj0U",
        "colab_type": "code",
        "outputId": "88d06990-b414-4e0d-ea6c-985d5678ac20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "flatten_word_simbols = [word_simbol for sublist in sentences for word_simbol in sublist]\n",
        "\n",
        "len(flatten_word_simbols)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "220482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "taf3spVVuj0m",
        "colab_type": "code",
        "outputId": "4b228ab2-97c3-4db1-e63d-3a039aef1066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "cnt = collections.Counter(flatten_word_simbols)\n",
        "print(\"Vocab size = \", len(cnt))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size =  19779\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S9nBX_tMuj01",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_keys = cnt.most_common()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V6FAIiuuuj1K",
        "colab_type": "code",
        "outputId": "c2ec3121-f0ad-46f4-9859-dd2fcda01c0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_keys[-1]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('semanaaaa', 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "rG3pymnAuj1Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stoi = {}\n",
        "\n",
        "i = 0\n",
        "for word_simbol, count in vocab_keys:\n",
        "    stoi[word_simbol] = i\n",
        "    i+=1\n",
        "    \n",
        "stoi['_end_'  ] = i\n",
        "#stoi['_blank_'] = i + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ml7-si74uj1j",
        "colab_type": "code",
        "outputId": "14d0cf6d-aace-4ce6-e0cf-68d3509785b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "stoi['que'],stoi['ja'],stoi['_end_']#, stoi['.'], stoi['_blank_']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 1779, 19779)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "r30WQbq-uj11",
        "colab_type": "code",
        "outputId": "14df6406-bda8-4109-c5cf-31672d4ed03d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Max key-value \\t= \", len(stoi.keys())-1)\n",
        "\n",
        "VOCAB_SIZE = len(stoi.keys())\n",
        "print(\"Vocab Size \\t= \", VOCAB_SIZE)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max key-value \t=  19779\n",
            "Vocab Size \t=  19780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ps6dU7Chuj1-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "itos = {}\n",
        "\n",
        "for s, i in stoi.items():\n",
        "    itos[i] = s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6fvl5udRuj2H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert ('que'     == itos[stoi['que'    ]])\n",
        "assert ('ja'      == itos[stoi['ja'     ]])\n",
        "#assert ('.'       == itos[stoi['.'      ]])\n",
        "assert ('_end_'   == itos[stoi['_end_'  ]])\n",
        "#assert ('_blank_' == itos[stoi['_blank_']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_1m5K892uj2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_input = []\n",
        "ls      = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    i_sentence = []\n",
        "    for word_simbol in sentence:\n",
        "        i_sentence.append(stoi[word_simbol])\n",
        "    i_sentence.append(stoi['_end_'])\n",
        "    x_input.append(i_sentence)\n",
        "    ls.append(len(i_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t1tjk15_uj2Z",
        "colab_type": "code",
        "outputId": "49bfe611-5bc3-4df5-f962-dd52fc5597bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "MAXLEN = max(ls)\n",
        "print('MAXLEN :',MAXLEN)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAXLEN : 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zIIhdlyuuj2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#blank_value = stoi['_blank_']\n",
        "#print('Blank Value = ', blank_value)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WgITTGVuj3H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#x_train = pad_sequences(x_input, maxlen = MAXLEN, value=blank_value)\n",
        "\n",
        "#print('Shape of data train tensor:', x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u11UyxdMwjRJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#x_input[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EpTPxJ7BxpHj",
        "colab_type": "code",
        "outputId": "4cf83687-62bb-4029-9e6b-67a95baf1044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "stoi['_end_']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19779"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "hgYGke4wuj3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_seq  = []\n",
        "y_train_next = []\n",
        "\n",
        "SEQ_LEN      = 3\n",
        "\n",
        "for x_input_obs in x_input:\n",
        "    MAXLEN = len(x_input_obs)\n",
        "    for i in range(MAXLEN - SEQ_LEN):\n",
        "        x_train_seq.append(x_input_obs[i:i+SEQ_LEN])\n",
        "        y_train_next.append(x_input_obs[i+SEQ_LEN])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O86HIygQxA4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for i in range(len(x_train_seq)):\n",
        "#  print(x_train_seq[i], '->', y_train_next[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CseQQZBmx5i2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gp0vcomJytFB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip3 install keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P98P3Wr8uj3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0090e04-ee34-4dd8-dbd4-e05459f8e116"
      },
      "cell_type": "code",
      "source": [
        "#import tensorflow as tf\n",
        "import keras \n",
        "\n",
        "#from keras import backend as K\n",
        "\n",
        "#print(K.tensorflow_backend._get_available_gpus())\n",
        "\n",
        "\n",
        "#config = tf.ConfigProto(allow_soft_placement = True, \n",
        "#                        device_count = {'CPU' : 1, 'GPU' : 0})\n",
        "\n",
        "#sess = tf.Session(config=config)\n",
        "\n",
        "#K.set_session(sess)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "cZJWLoDnuj35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#from keras.utils import to_categorical\n",
        "from keras.layers import LSTM, Input, Bidirectional, Dropout, Dense, Activation\n",
        "from keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xUnKIkOOuj4G",
        "colab_type": "code",
        "outputId": "0a9b5f41-1070-4718-c2e9-8d1ace7ad72a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "cell_type": "code",
      "source": [
        "seq_input = Input(shape=(SEQ_LEN, VOCAB_SIZE))\n",
        "\n",
        "rnn       = Bidirectional(LSTM(128, activation=\"relu\"))(seq_input)\n",
        "#rnn       = LSTM(128, activation=\"relu\")(seq_input)\n",
        "rnn       = Dropout(0.5)(rnn)\n",
        "rnn       = Dense(VOCAB_SIZE)(rnn)\n",
        "output    = Activation('softmax')(rnn)\n",
        "\n",
        "model     = Model(inputs=[seq_input], outputs=[output])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 3, 19780)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               20386816  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 19780)             5083460   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 19780)             0         \n",
            "=================================================================\n",
            "Total params: 25,470,276\n",
            "Trainable params: 25,470,276\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "svYJwvJ33HUj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def X_to_OneHot(batch_sentences, num_classes):\n",
        "  output = np.zeros((len(batch_sentences), SEQ_LEN, num_classes), dtype=np.bool)\n",
        "  \n",
        "  for i,sentence in enumerate(batch_sentences):\n",
        "    for k,value in enumerate(sentence):\n",
        "      output[i, k, value] = 1\n",
        "  \n",
        "  return output\n",
        "\n",
        "def Y_to_OneHot(batch_label, num_classes):\n",
        "  output = np.zeros((len(batch_label), num_classes), dtype=np.bool)\n",
        "  \n",
        "  for i, label in enumerate(batch_label):\n",
        "    output[i, label] = 1\n",
        "  \n",
        "  return output  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RA_Y4h4W3Vfr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#xp = X_to_OneHot(x_train_seq[:10], VOCAB_SIZE)\n",
        "#yp = Y_to_OneHot(y_train_next[:10], VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ojt3urhr5Mxn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#assert (np.argmax(xp[0,1,:]) == x_train_seq[0][1])\n",
        "#assert (np.argmax(yp[0,:]) == y_train_next[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f2FMLQ9_-UCg",
        "colab_type": "code",
        "outputId": "ab23f746-fb4a-45d5-9d1e-0c832fa7911b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(x_train_seq)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200482"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "uYmSWbqsEBEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.load_weights(DRIVE_PATH+'model/textG_best_weights.02-7.3152.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lIwr0_UYuj4Q",
        "colab_type": "code",
        "outputId": "2bdba0b3-1ef0-453e-afd6-8509a8a995d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "BATCH_SIZE = 10000\n",
        "\n",
        "filepath   = DRIVE_PATH + \"model/textG_best_weights.{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, mode='auto', period=2)\n",
        "\n",
        "n_epoch = 10\n",
        "\n",
        "for ie in range(n_epoch):\n",
        "  print(\"\\nEPOCH : \", ie,end=' ===========================\\n\\n')\n",
        "  for ibatch in range(0, len(x_train_seq), BATCH_SIZE):\n",
        "      i_begin = ibatch\n",
        "      i_end   = min(ibatch + BATCH_SIZE, len(x_train_seq))\n",
        "\n",
        "      #print('BATCH', i_begin, '-',i_end)\n",
        "      x_train_one_hot = X_to_OneHot( x_train_seq[i_begin:i_end], num_classes = VOCAB_SIZE)\n",
        "      y_train_one_hot = Y_to_OneHot(y_train_next[i_begin:i_end], num_classes = VOCAB_SIZE)  \n",
        "      \n",
        "      model.fit(x_train_one_hot, y_train_one_hot, \n",
        "                batch_size=256, \n",
        "                shuffle=True, \n",
        "                epochs=2,\n",
        "                callbacks = [checkpoint],\n",
        "                validation_split=0.1)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "EPOCH :  0 ===========================\n",
            "\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 10s 1ms/step - loss: 3.7899 - categorical_accuracy: 0.2918 - val_loss: 6.4853 - val_categorical_accuracy: 0.1290\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 744us/step - loss: 3.5189 - categorical_accuracy: 0.3181 - val_loss: 6.5338 - val_categorical_accuracy: 0.1390\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 741us/step - loss: 3.8054 - categorical_accuracy: 0.2886 - val_loss: 6.3058 - val_categorical_accuracy: 0.1500\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 763us/step - loss: 3.5345 - categorical_accuracy: 0.3218 - val_loss: 6.3574 - val_categorical_accuracy: 0.1490\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 742us/step - loss: 3.8244 - categorical_accuracy: 0.2933 - val_loss: 6.8071 - val_categorical_accuracy: 0.1160\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 755us/step - loss: 3.5725 - categorical_accuracy: 0.3214 - val_loss: 6.8855 - val_categorical_accuracy: 0.1190\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 746us/step - loss: 3.8689 - categorical_accuracy: 0.2899 - val_loss: 6.7698 - val_categorical_accuracy: 0.1090\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 765us/step - loss: 3.6081 - categorical_accuracy: 0.3163 - val_loss: 6.8199 - val_categorical_accuracy: 0.1090\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 741us/step - loss: 3.9048 - categorical_accuracy: 0.2919 - val_loss: 6.6888 - val_categorical_accuracy: 0.1060\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 750us/step - loss: 3.6337 - categorical_accuracy: 0.3191 - val_loss: 6.7852 - val_categorical_accuracy: 0.1130\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 736us/step - loss: 3.9385 - categorical_accuracy: 0.2856 - val_loss: 6.7129 - val_categorical_accuracy: 0.1160\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 753us/step - loss: 3.6489 - categorical_accuracy: 0.3218 - val_loss: 6.7924 - val_categorical_accuracy: 0.1170\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 736us/step - loss: 4.0127 - categorical_accuracy: 0.2870 - val_loss: 6.5033 - val_categorical_accuracy: 0.1200\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 750us/step - loss: 3.7306 - categorical_accuracy: 0.3254 - val_loss: 6.5683 - val_categorical_accuracy: 0.1150\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 737us/step - loss: 4.0129 - categorical_accuracy: 0.2967 - val_loss: 6.5040 - val_categorical_accuracy: 0.1530\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 753us/step - loss: 3.7388 - categorical_accuracy: 0.3189 - val_loss: 6.5681 - val_categorical_accuracy: 0.1470\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 748us/step - loss: 4.0680 - categorical_accuracy: 0.2959 - val_loss: 6.5277 - val_categorical_accuracy: 0.1470\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 761us/step - loss: 3.7847 - categorical_accuracy: 0.3252 - val_loss: 6.5641 - val_categorical_accuracy: 0.1380\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "9000/9000 [==============================] - 7s 747us/step - loss: 4.0829 - categorical_accuracy: 0.2981 - val_loss: 6.6415 - val_categorical_accuracy: 0.1140\n",
            "Epoch 2/2\n",
            "9000/9000 [==============================] - 7s 763us/step - loss: 3.8045 - categorical_accuracy: 0.3240 - val_loss: 6.6845 - val_categorical_accuracy: 0.1160\n",
            "Train on 9000 samples, validate on 1000 samples\n",
            "Epoch 1/2\n",
            "7168/9000 [======================>.......] - ETA: 1s - loss: 4.1023 - categorical_accuracy: 0.2879"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BdQNiWjcuj4W",
        "colab_type": "code",
        "outputId": "d5ff0497-e692-4f00-afdd-f5c3fe147f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "text = 'creo que ya'\n",
        "seq  = [[stoi[word] for word in text.split()[-3:]]]\n",
        "\n",
        "print(text, end=' ')\n",
        "for i in range(10):\n",
        "  val  = np.argmax(model.predict(X_to_OneHot(seq, VOCAB_SIZE)))\n",
        "  if itos[val] == '_end_':\n",
        "    break\n",
        "  print(itos[val], end=' ')\n",
        "  \n",
        "  M = seq[0][1:]\n",
        "  M.append(val)\n",
        "  seq = [M]\n",
        "  #print(seq)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creo que ya me voy a dormir "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zRr__lrGBxnT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
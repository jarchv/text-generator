{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ALDvLowpumX3",
    "outputId": "107861d0-46f9-4336-9073-7c3ebc8e8bce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive \n",
    "\n",
    "\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MawPHZSvEZw"
   },
   "outputs": [],
   "source": [
    "DRIVE_PATH = '/content/gdrive/My Drive/CS/SI/part2/text-generator/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9jb4572ujzD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(DRIVE_PATH + \"spanish_emojis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "VxfxjGFhujzb",
    "outputId": "649c49cc-1896-4503-fbcf-ea479c7ee97f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>emojis</th>\n",
       "      <th>observations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>üò≠</td>\n",
       "      <td>? en serio han cancelado tambien quantico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>si on mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>302</td>\n",
       "      <td>üòù</td>\n",
       "      <td>se duerme relooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>303</td>\n",
       "      <td>ü§ó</td>\n",
       "      <td>ahi te podes dar cuenta que diferentes somos y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>304</td>\n",
       "      <td>üò™</td>\n",
       "      <td>625 pero la tipi esta jugando desde la 5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 emojis                                       observations\n",
       "0         300      üò≠          ? en serio han cancelado tambien quantico\n",
       "1         301      üòÇ                                           si on mo\n",
       "2         302      üòù                                   se duerme relooo\n",
       "3         303      ü§ó  ahi te podes dar cuenta que diferentes somos y...\n",
       "4         304      üò™           625 pero la tipi esta jugando desde la 5"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bjNy5CiQujzt",
    "outputId": "ad16eca8-33ad-407a-dd3c-256ab45b4df7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151743"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = df['observations'].values\n",
    "len(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NESyBZ99ujz-",
    "outputId": "6c8d079b-0959-4482-9763-cb76e26cbda7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? en serio han cancelado tambien quantico'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zOus-1euuj0L",
    "outputId": "c9bbe422-0e51-44b9-f228-6be809577782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13336\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in observations:\n",
    "    if len(sentence.split()) > 18:\n",
    "      sentences.append(sentence.split())\n",
    "      \n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bg0cOyjnvdSE"
   },
   "outputs": [],
   "source": [
    "sentences = sentences[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MZUjgxnfuj0U",
    "outputId": "8ca26854-85b1-4b94-8fea-eef359b06756"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220482"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_word_simbols = [word_simbol for sublist in sentences for word_simbol in sublist]\n",
    "\n",
    "len(flatten_word_simbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "taf3spVVuj0m",
    "outputId": "e01dd907-c2b1-4130-de6a-bdde999eab64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size =  19779\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "cnt = collections.Counter(flatten_word_simbols)\n",
    "print(\"Vocab size = \", len(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S9nBX_tMuj01"
   },
   "outputs": [],
   "source": [
    "vocab_keys = cnt.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V6FAIiuuuj1K",
    "outputId": "10c74920-fae1-4575-9944-6a82fd95ec5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('semanaaaa', 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_keys[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rG3pymnAuj1Z"
   },
   "outputs": [],
   "source": [
    "stoi = {}\n",
    "\n",
    "i = 0\n",
    "for word_simbol, count in vocab_keys:\n",
    "    stoi[word_simbol] = i\n",
    "    i+=1\n",
    "    \n",
    "stoi['_end_'  ] = i\n",
    "#stoi['_blank_'] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ml7-si74uj1j",
    "outputId": "6f5a8597-7154-4f4c-f559-0025138245bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1779, 19779)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['que'],stoi['ja'],stoi['_end_']#, stoi['.'], stoi['_blank_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "r30WQbq-uj11",
    "outputId": "0e8b2fa3-b806-408b-cf20-46b8985e07cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max key-value \t=  19779\n",
      "Vocab Size \t=  19780\n"
     ]
    }
   ],
   "source": [
    "print(\"Max key-value \\t= \", len(stoi.keys())-1)\n",
    "\n",
    "VOCAB_SIZE = len(stoi.keys())\n",
    "print(\"Vocab Size \\t= \", VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ps6dU7Chuj1-"
   },
   "outputs": [],
   "source": [
    "itos = {}\n",
    "\n",
    "for s, i in stoi.items():\n",
    "    itos[i] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fvl5udRuj2H"
   },
   "outputs": [],
   "source": [
    "assert ('que'     == itos[stoi['que'    ]])\n",
    "assert ('ja'      == itos[stoi['ja'     ]])\n",
    "#assert ('.'       == itos[stoi['.'      ]])\n",
    "assert ('_end_'   == itos[stoi['_end_'  ]])\n",
    "#assert ('_blank_' == itos[stoi['_blank_']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1m5K892uj2Q"
   },
   "outputs": [],
   "source": [
    "x_input = []\n",
    "ls      = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    i_sentence = []\n",
    "    for word_simbol in sentence:\n",
    "        i_sentence.append(stoi[word_simbol])\n",
    "    i_sentence.append(stoi['_end_'])\n",
    "    x_input.append(i_sentence)\n",
    "    ls.append(len(i_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "t1tjk15_uj2Z",
    "outputId": "94ca2406-3370-4253-9374-f6eb51b4d70d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAXLEN : 50\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = max(ls)\n",
    "print('MAXLEN :',MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIIhdlyuuj2w"
   },
   "outputs": [],
   "source": [
    "#blank_value = stoi['_blank_']\n",
    "#print('Blank Value = ', blank_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WgITTGVuj3H"
   },
   "outputs": [],
   "source": [
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#x_train = pad_sequences(x_input, maxlen = MAXLEN, value=blank_value)\n",
    "\n",
    "#print('Shape of data train tensor:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u11UyxdMwjRJ"
   },
   "outputs": [],
   "source": [
    "#x_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EpTPxJ7BxpHj",
    "outputId": "77cf587d-5888-453b-9458-ee1c35751491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19779"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['_end_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgYGke4wuj3Z"
   },
   "outputs": [],
   "source": [
    "x_train_seq  = []\n",
    "y_train_next = []\n",
    "\n",
    "SEQ_LEN      = 3\n",
    "\n",
    "for x_input_obs in x_input:\n",
    "    MAXLEN = len(x_input_obs)\n",
    "    for i in range(MAXLEN - SEQ_LEN):\n",
    "        x_train_seq.append(x_input_obs[i:i+SEQ_LEN])\n",
    "        y_train_next.append(x_input_obs[i+SEQ_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O86HIygQxA4p"
   },
   "outputs": [],
   "source": [
    "#for i in range(len(x_train_seq)):\n",
    "#  print(x_train_seq[i], '->', y_train_next[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CseQQZBmx5i2"
   },
   "outputs": [],
   "source": [
    "!pip install -q keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gp0vcomJytFB"
   },
   "outputs": [],
   "source": [
    "#!pip3 install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "P98P3Wr8uj3x",
    "outputId": "5f884ab9-62e6-4864-9db2-162dac22bed1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import keras \n",
    "\n",
    "#from keras import backend as K\n",
    "\n",
    "#print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "\n",
    "#config = tf.ConfigProto(allow_soft_placement = True, \n",
    "#                        device_count = {'CPU' : 1, 'GPU' : 0})\n",
    "\n",
    "#sess = tf.Session(config=config)\n",
    "\n",
    "#K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZJWLoDnuj35"
   },
   "outputs": [],
   "source": [
    "#from keras.utils import to_categorical\n",
    "from keras.layers import LSTM, Input, Bidirectional, Dropout, Dense, Activation\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "xUnKIkOOuj4G",
    "outputId": "58c4102e-3820-42f4-a3a1-d5b34a5b7ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 19780)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               10193408  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 19780)             2551620   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 19780)             0         \n",
      "=================================================================\n",
      "Total params: 12,745,028\n",
      "Trainable params: 12,745,028\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq_input = Input(shape=(SEQ_LEN, VOCAB_SIZE))\n",
    "\n",
    "#rnn       = Bidirectional(LSTM(SEQ_LEN, activation=\"relu\"))(seq_input)\n",
    "rnn       = LSTM(128, activation=\"relu\")(seq_input)\n",
    "rnn       = Dropout(0.6)(rnn)\n",
    "rnn       = Dense(VOCAB_SIZE)(rnn)\n",
    "output    = Activation('softmax')(rnn)\n",
    "\n",
    "model     = Model(inputs=[seq_input], outputs=[output])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svYJwvJ33HUj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def X_to_OneHot(batch_sentences, num_classes):\n",
    "  output = np.zeros((len(batch_sentences), SEQ_LEN, num_classes), dtype=np.bool)\n",
    "  \n",
    "  for i,sentence in enumerate(batch_sentences):\n",
    "    for k,value in enumerate(sentence):\n",
    "      output[i, k, value] = 1\n",
    "  \n",
    "  return output\n",
    "\n",
    "def Y_to_OneHot(batch_label, num_classes):\n",
    "  output = np.zeros((len(batch_label), num_classes), dtype=np.bool)\n",
    "  \n",
    "  for i, label in enumerate(batch_label):\n",
    "    output[i, label] = 1\n",
    "  \n",
    "  return output  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RA_Y4h4W3Vfr"
   },
   "outputs": [],
   "source": [
    "xp = X_to_OneHot(x_train_seq[:10], VOCAB_SIZE)\n",
    "yp = Y_to_OneHot(y_train_next[:10], VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ojt3urhr5Mxn"
   },
   "outputs": [],
   "source": [
    "assert (np.argmax(xp[0,1,:]) == x_train_seq[0][1])\n",
    "assert (np.argmax(yp[0,:]) == y_train_next[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f2FMLQ9_-UCg",
    "outputId": "dfd4cad9-28fe-4e3b-f1be-b6f637d8877e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200482"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYmSWbqsEBEN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5252
    },
    "colab_type": "code",
    "id": "lIwr0_UYuj4Q",
    "outputId": "bd205770-5d1f-4630-837c-eda693b339e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH 0 - 10000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 8s 840us/step - loss: 8.8822 - categorical_accuracy: 0.0395\n",
      "BATCH 10000 - 20000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 632us/step - loss: 6.8690 - categorical_accuracy: 0.0489\n",
      "BATCH 20000 - 30000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 6.7947 - categorical_accuracy: 0.0484\n",
      "BATCH 30000 - 40000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 6.7439 - categorical_accuracy: 0.0487\n",
      "BATCH 40000 - 50000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 6.7257 - categorical_accuracy: 0.0492\n",
      "BATCH 50000 - 60000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 652us/step - loss: 6.6806 - categorical_accuracy: 0.0470\n",
      "BATCH 60000 - 70000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 6.7098 - categorical_accuracy: 0.0490\n",
      "BATCH 70000 - 80000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 6.6562 - categorical_accuracy: 0.0506\n",
      "BATCH 80000 - 90000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 657us/step - loss: 6.6698 - categorical_accuracy: 0.0503\n",
      "BATCH 90000 - 100000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 6.6716 - categorical_accuracy: 0.0504\n",
      "BATCH 100000 - 110000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 641us/step - loss: 6.5605 - categorical_accuracy: 0.0499\n",
      "BATCH 110000 - 120000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 633us/step - loss: 6.5840 - categorical_accuracy: 0.0498\n",
      "BATCH 120000 - 130000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 6.5922 - categorical_accuracy: 0.0499\n",
      "BATCH 130000 - 140000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 6.5649 - categorical_accuracy: 0.0488\n",
      "BATCH 140000 - 150000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 646us/step - loss: 6.5970 - categorical_accuracy: 0.0500\n",
      "BATCH 150000 - 160000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 6.6038 - categorical_accuracy: 0.0486\n",
      "BATCH 160000 - 170000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 657us/step - loss: 6.5354 - categorical_accuracy: 0.0492\n",
      "BATCH 170000 - 180000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 648us/step - loss: 6.5940 - categorical_accuracy: 0.0500\n",
      "BATCH 180000 - 190000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 6.4933 - categorical_accuracy: 0.0496\n",
      "BATCH 190000 - 200000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 6.4686 - categorical_accuracy: 0.0499\n",
      "BATCH 200000 - 200482\n",
      "Epoch 1/1\n",
      "482/482 [==============================] - 0s 668us/step - loss: 6.4626 - categorical_accuracy: 0.0643\n",
      "BATCH 0 - 10000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 657us/step - loss: 6.3690 - categorical_accuracy: 0.0481\n",
      "BATCH 10000 - 20000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 632us/step - loss: 6.4570 - categorical_accuracy: 0.0498\n",
      "BATCH 20000 - 30000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 657us/step - loss: 6.4985 - categorical_accuracy: 0.0504\n",
      "BATCH 30000 - 40000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 6.4831 - categorical_accuracy: 0.0507\n",
      "BATCH 40000 - 50000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 656us/step - loss: 6.4948 - categorical_accuracy: 0.0502\n",
      "BATCH 50000 - 60000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 630us/step - loss: 6.4530 - categorical_accuracy: 0.0511\n",
      "BATCH 60000 - 70000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 6.5059 - categorical_accuracy: 0.0523\n",
      "BATCH 70000 - 80000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 6.4750 - categorical_accuracy: 0.0504\n",
      "BATCH 80000 - 90000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 6.5051 - categorical_accuracy: 0.0530\n",
      "BATCH 90000 - 100000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 628us/step - loss: 6.5191 - categorical_accuracy: 0.0539\n",
      "BATCH 100000 - 110000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 657us/step - loss: 6.4273 - categorical_accuracy: 0.0490\n",
      "BATCH 110000 - 120000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 632us/step - loss: 6.4681 - categorical_accuracy: 0.0510\n",
      "BATCH 120000 - 130000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 6.4723 - categorical_accuracy: 0.0557\n",
      "BATCH 130000 - 140000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 6.4647 - categorical_accuracy: 0.0531\n",
      "BATCH 140000 - 150000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 6.4997 - categorical_accuracy: 0.0557\n",
      "BATCH 150000 - 160000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 629us/step - loss: 6.4904 - categorical_accuracy: 0.0577\n",
      "BATCH 160000 - 170000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 6.4303 - categorical_accuracy: 0.0547\n",
      "BATCH 170000 - 180000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 632us/step - loss: 6.5092 - categorical_accuracy: 0.0582\n",
      "BATCH 180000 - 190000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 655us/step - loss: 6.3968 - categorical_accuracy: 0.0643\n",
      "BATCH 190000 - 200000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 6.3610 - categorical_accuracy: 0.0664\n",
      "BATCH 200000 - 200482\n",
      "Epoch 1/1\n",
      "482/482 [==============================] - 0s 654us/step - loss: 6.3845 - categorical_accuracy: 0.0643\n",
      "BATCH 0 - 10000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 6.3173 - categorical_accuracy: 0.0723\n",
      "BATCH 10000 - 20000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 633us/step - loss: 6.3873 - categorical_accuracy: 0.0694\n",
      "BATCH 20000 - 30000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 6.4218 - categorical_accuracy: 0.0652\n",
      "BATCH 30000 - 40000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 632us/step - loss: 6.4035 - categorical_accuracy: 0.0734\n",
      "BATCH 40000 - 50000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 6.4074 - categorical_accuracy: 0.0762\n",
      "BATCH 50000 - 60000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 6.3636 - categorical_accuracy: 0.0766\n",
      "BATCH 60000 - 70000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 642us/step - loss: 6.3999 - categorical_accuracy: 0.0774\n",
      "BATCH 70000 - 80000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 6.3670 - categorical_accuracy: 0.0782\n",
      "BATCH 80000 - 90000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 642us/step - loss: 6.3942 - categorical_accuracy: 0.0815\n",
      "BATCH 90000 - 100000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 6.3979 - categorical_accuracy: 0.0810\n",
      "BATCH 100000 - 110000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 6.2983 - categorical_accuracy: 0.0827\n",
      "BATCH 110000 - 120000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 6.3336 - categorical_accuracy: 0.0872\n",
      "BATCH 120000 - 130000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 6.3420 - categorical_accuracy: 0.0861\n",
      "BATCH 130000 - 140000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 6.3145 - categorical_accuracy: 0.0875\n",
      "BATCH 140000 - 150000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 6.3598 - categorical_accuracy: 0.0874\n",
      "BATCH 150000 - 160000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 630us/step - loss: 6.3507 - categorical_accuracy: 0.0844\n",
      "BATCH 160000 - 170000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 6.2820 - categorical_accuracy: 0.0910\n",
      "BATCH 170000 - 180000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 6.3633 - categorical_accuracy: 0.0879\n",
      "BATCH 180000 - 190000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 6.2431 - categorical_accuracy: 0.0964\n",
      "BATCH 190000 - 200000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 6.2074 - categorical_accuracy: 0.1002\n",
      "BATCH 200000 - 200482\n",
      "Epoch 1/1\n",
      "482/482 [==============================] - 0s 655us/step - loss: 6.2641 - categorical_accuracy: 0.0892\n",
      "BATCH 0 - 10000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 719us/step - loss: 6.1844 - categorical_accuracy: 0.0941\n",
      "BATCH 10000 - 20000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 6.2403 - categorical_accuracy: 0.0961\n",
      "BATCH 20000 - 30000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 661us/step - loss: 6.2760 - categorical_accuracy: 0.0901\n",
      "BATCH 30000 - 40000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 638us/step - loss: 6.2421 - categorical_accuracy: 0.0959\n",
      "BATCH 40000 - 50000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 6.2471 - categorical_accuracy: 0.0964\n",
      "BATCH 50000 - 60000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 6.1954 - categorical_accuracy: 0.0959\n",
      "BATCH 60000 - 70000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 669us/step - loss: 6.2447 - categorical_accuracy: 0.0978\n",
      "BATCH 70000 - 80000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 6.2263 - categorical_accuracy: 0.0962\n",
      "BATCH 80000 - 90000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 666us/step - loss: 6.2454 - categorical_accuracy: 0.1003\n",
      "BATCH 90000 - 100000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 633us/step - loss: 6.2488 - categorical_accuracy: 0.0992\n",
      "BATCH 100000 - 110000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 661us/step - loss: 6.1436 - categorical_accuracy: 0.1011\n",
      "BATCH 110000 - 120000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 6.1769 - categorical_accuracy: 0.1056\n",
      "BATCH 120000 - 130000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 671us/step - loss: 6.1823 - categorical_accuracy: 0.1017\n",
      "BATCH 130000 - 140000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 6.1714 - categorical_accuracy: 0.1063\n",
      "BATCH 140000 - 150000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 665us/step - loss: 6.1965 - categorical_accuracy: 0.1037\n",
      "BATCH 150000 - 160000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 6.1817 - categorical_accuracy: 0.1000\n",
      "BATCH 160000 - 170000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 667us/step - loss: 6.1210 - categorical_accuracy: 0.1079\n",
      "BATCH 170000 - 180000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 6.1987 - categorical_accuracy: 0.1043\n",
      "BATCH 180000 - 190000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 664us/step - loss: 6.0794 - categorical_accuracy: 0.1102\n",
      "BATCH 190000 - 200000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 633us/step - loss: 6.0206 - categorical_accuracy: 0.1165\n",
      "BATCH 200000 - 200482\n",
      "Epoch 1/1\n",
      "482/482 [==============================] - 0s 679us/step - loss: 6.1569 - categorical_accuracy: 0.1058\n",
      "BATCH 0 - 10000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 652us/step - loss: 6.0283 - categorical_accuracy: 0.1134\n",
      "BATCH 10000 - 20000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 6.0935 - categorical_accuracy: 0.1111\n",
      "BATCH 20000 - 30000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 651us/step - loss: 6.1194 - categorical_accuracy: 0.1052\n",
      "BATCH 30000 - 40000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 6.0881 - categorical_accuracy: 0.1080\n",
      "BATCH 40000 - 50000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 7s 651us/step - loss: 6.1024 - categorical_accuracy: 0.1096\n",
      "BATCH 50000 - 60000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 6.0513 - categorical_accuracy: 0.1104\n",
      "BATCH 60000 - 70000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 648us/step - loss: 6.1008 - categorical_accuracy: 0.1065\n",
      "BATCH 70000 - 80000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 6.0699 - categorical_accuracy: 0.1102\n",
      "BATCH 80000 - 90000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 646us/step - loss: 6.0913 - categorical_accuracy: 0.1092\n",
      "BATCH 90000 - 100000\n",
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 6s 632us/step - loss: 6.0960 - categorical_accuracy: 0.1105\n",
      "BATCH 100000 - 110000\n",
      "Epoch 1/1\n",
      " 2688/10000 [=======>......................] - ETA: 4s - loss: 5.9670 - categorical_accuracy: 0.1190"
     ]
    }
   ],
   "source": [
    "#from keras.callbacks import ModelCheckpoint\n",
    "#import numpy as np\n",
    "\n",
    "BATCH_SIZE = 10000\n",
    "\n",
    "#filepath   =\"model/textG_best_weights_SIF.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "n_epoch = 10\n",
    "\n",
    "for _ in range(n_epoch):\n",
    "  for ibatch in range(0, len(x_train_seq), BATCH_SIZE):\n",
    "      i_begin = ibatch\n",
    "      i_end   = min(ibatch + BATCH_SIZE, len(x_train_seq))\n",
    "\n",
    "      print('BATCH', i_begin, '-',i_end)\n",
    "      x_train_one_hot = X_to_OneHot( x_train_seq[i_begin:i_end], num_classes = VOCAB_SIZE)\n",
    "      y_train_one_hot = Y_to_OneHot(y_train_next[i_begin:i_end], num_classes = VOCAB_SIZE)\n",
    "      #x_train_one_hot = np.reshape(x_train_one_hot, (x_train_one_hot.shape[0],VOCAB_SIZE, SEQ_LEN))\n",
    "      #model.fit(x_train_one_hot, y_train_one_hot, batch_size=64, epochs=1, callbacks = [checkpoint])   \n",
    "      model.fit(x_train_one_hot, y_train_one_hot, batch_size=128, epochs=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BYZtfPCcAlAa",
    "outputId": "1780d961-bffe-4e14-81e4-2876437f4ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result =  que\n"
     ]
    }
   ],
   "source": [
    "text = 'hola como estas'\n",
    "\n",
    "seq  = [[stoi[word] for word in text.split()]]\n",
    "\n",
    "val  = np.argmax(model.predict(X_to_OneHot(seq, VOCAB_SIZE)))\n",
    "\n",
    "print('result = ', itos[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "BdQNiWjcuj4W",
    "outputId": "d7271dfb-76a9-473b-8a68-54fde554ed53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola como estas que que que que que que que que que que "
     ]
    }
   ],
   "source": [
    "test = 'hola como estas'\n",
    "seq  = [[stoi[word] for word in text.split()]]\n",
    "\n",
    "#print(seq)\n",
    "print(text, end=' ')\n",
    "for i in range(10):\n",
    "  val  = np.argmax(model.predict(X_to_OneHot(seq, VOCAB_SIZE)))\n",
    "  print(itos[val], end=' ')\n",
    "  M = seq[0][1:]\n",
    "  M.append(val)\n",
    "  seq = [M]\n",
    "  #print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRr__lrGBxnT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "textGenerator.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
